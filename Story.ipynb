{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ccfa58-f2a8-4b22-8464-4342d5aabd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NVAPI Key (starts with nvapi-):  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\n",
    "        \"nvapi-\"\n",
    "    ), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbd176f-d382-4135-8b4d-fd7a60ad1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557571ce-58cb-41b9-a2cd-c2a2d80280fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pydantic import BaseModel, Field\n",
    "#from pydantic_core import from_json\n",
    "#from typing import List\n",
    "from prompts import STORY_JSON_PROMPT, STORY_GENERATE_IMAGE_PROMPT, SAFE_STORY_PROMPT, EXTRACT_SUMMARIZE_STORY_PROMPT\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import  SimpleDirectoryReader, ServiceContext, SummaryIndex\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "from llama_index.core.workflow.retry_policy import ConstantDelayRetryPolicy\n",
    "    \n",
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core.response_synthesizers import SimpleSummarize\n",
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from image_gen import (generate_image, base64_to_imagefile)\n",
    "from utils import (write_file, read_file, has_file, save_url_data)\n",
    "\n",
    "from events import (ChildrenStoryEvent, PromptEvent, PDFEvent, StorySummaryEvent, BookImageEvent, AudioEvent)\n",
    "\n",
    "\n",
    "Settings.llm = NVIDIA(model=\"meta/llama3-70b-instruct\")\n",
    "\n",
    "\n",
    "DATA_PATH = './data'\n",
    "IMAGE_PATH = 'image'\n",
    "AUDIO_PATH = 'audio'\n",
    "VIDEO_PATH = 'video'\n",
    "RAW_STORY_FILE = 'raw_story.txt'\n",
    "STORY_JSON_FILE = 'story.json'\n",
    "STORY_PDF_FILE = 'story.pdf'\n",
    "TITLE_PROMPT_FILE = 'title_prompt.txt'\n",
    "VIDEO_NAME = 'story_video.mp4'\n",
    "CREATE_PDF = False\n",
    "\n",
    "class ChildrenStoryGenerationWorkflow(Workflow):\n",
    "    @step\n",
    "    async def read_story(self, ev: StartEvent) -> ChildrenStoryEvent|PromptEvent|PDFEvent|StorySummaryEvent|StopEvent:\n",
    "        CREATE_PDF = ev.pdf\n",
    "        if len(ev.url) > 0: \n",
    "            save_url_data(ev.url, f'{DATA_PATH}/{RAW_STORY_FILE}')\n",
    "            return StartEvent(url='')\n",
    "        elif has_file(DATA_PATH, STORY_JSON_FILE) and has_file(DATA_PATH, STORY_PDF_FILE):\n",
    "            story = read_story_json(f'{DATA_PATH}/{STORY_JSON_FILE}')\n",
    "            return PDFEvent(story = story, path=f'{DATA_PATH}/{STORY_PDF_FILE}')\n",
    "        elif has_file(DATA_PATH, STORY_JSON_FILE):\n",
    "            story = read_story_json(f'{DATA_PATH}/{STORY_JSON_FILE}')\n",
    "            if has_prompts(DATA_PATH, story):\n",
    "                return PromptEvent(path=DATA_PATH, story=story)\n",
    "            else:\n",
    "                return ChildrenStoryEvent(story=output)\n",
    "        elif has_file(DATA_PATH, RAW_STORY_FILE):\n",
    "            reader = SimpleDirectoryReader(input_files=[f'{DATA_PATH}/{RAW_STORY_FILE}'])\n",
    "            docs = reader.load_data()\n",
    "            texts = [d.text for d in docs]\n",
    "            summarizer = SimpleSummarize()\n",
    "            response = await summarizer.aget_response(EXTRACT_SUMMARIZE_STORY_PROMPT, texts)\n",
    "            return StorySummaryEvent(story=str(response))\n",
    "        else :\n",
    "            return StopEvent(result=\"{error:'Please specify url'}\")\n",
    "          \n",
    "    @step \n",
    "    async def create_guardrail(self, ev: StorySummaryEvent) -> StoryEvent:\n",
    "        config = RailsConfig.from_path('config')\n",
    "        rails = LLMRails(config)\n",
    "        template = PromptTemplate(SAFE_STORY_PROMPT)\n",
    "        prompt = template.format(story=ev.story)\n",
    "        res = await rails.generate_async(prompt=prompt)\n",
    "        return StoryEvent(story=str(res))\n",
    "    \n",
    "    @step #(retry_policy=ConstantDelayRetryPolicy(delay=5, maximum_attempts=5))\n",
    "    async def generate_json(self, ev: StoryEvent) -> ChildrenStoryEvent:\n",
    "        story = ev.story\n",
    "        #print(story)\n",
    "        program = LLMTextCompletionProgram.from_defaults(\n",
    "            output_parser=PydanticOutputParser(output_cls=ChildrenStory),\n",
    "            prompt_template_str=STORY_JSON_PROMPT,\n",
    "            verbose=True,\n",
    "        )\n",
    "        output:ChildrenStory = program(story=story)\n",
    "        write_file(output.json(), f'{DATA_PATH}/{STORY_JSON_FILE}')\n",
    "        return ChildrenStoryEvent(story=output)\n",
    "    \n",
    "    @step #(retry_policy=ConstantDelayRetryPolicy(delay=5, maximum_attempts=20))\n",
    "    async def generate_prompt(self, ev: ChildrenStoryEvent) -> PromptEvent:\n",
    "        story = ev.story\n",
    "        template = PromptTemplate(STORY_GENERATE_IMAGE_PROMPT)\n",
    "        prompt = template.format(page = \"title page\", story=get_full_story_with_title(story))\n",
    "\n",
    "        response = Settings.llm.complete(prompt)\n",
    "        write_file(response.text, f'{DATA_PATH}/{TITLE_PROMPT_FILE}')\n",
    "        for page in story.pages:\n",
    "            template = PromptTemplate(STORY_GENERATE_IMAGE_PROMPT)\n",
    "            prompt = template.format(page = f\"page_no {str(page.page_no)}\", story=get_full_story_with_title(story))\n",
    "\n",
    "            response = Settings.llm.complete(prompt)\n",
    "            write_file(response.text, f'{DATA_PATH}/{str(page.page_no)}_prompt.txt')\n",
    "        return PromptEvent(path=DATA_PATH, story=story)\n",
    "    @step\n",
    "    async def generate_image(self, ev: PromptEvent) -> BookImageEvent:\n",
    "        path = ev.path\n",
    "        story = ev.story\n",
    "        prompt = parse_prompt(f'{DATA_PATH}/{TITLE_PROMPT_FILE}')\n",
    "        outfile = f'{path}/{IMAGE_PATH}/title.jpg'\n",
    "        key = os.environ[\"NVIDIA_API_KEY\"]\n",
    "        base64_to_imagefile(generate_image(prompt, key), out_file)\n",
    "        \n",
    "        for i in range(len(story.pages)):\n",
    "            prompt = parse_prompt(f'{path}/{i+1}_prompt.txt')\n",
    "            outfile = f'{path}/{IMAGE_PATH}/{i+1}.jpg'\n",
    "            base64_to_imagefile(generate_image(prompt, key), out_file)\n",
    "        return BookImageEvent(story = story, path=f'{path}/{IMAGE_PATH}')\n",
    "    @step\n",
    "    async def generate_pdf(self, ev: BookImageEvent) -> PDFEvent|StopEvent:\n",
    "        create_pdf(f'{DATA_PATH}/{STORY_PDF_FILE}', ev.story, ev.path)\n",
    "        if CREATE_PDF:\n",
    "            return StopEvent(result=f'{DATA_PATH}/{STORY_PDF_FILE}')\n",
    "        else:\n",
    "            return PDFEvent(story = ev.story, path=f'{DATA_PATH}/{STORY_PDF_FILE}')\n",
    "\n",
    "    @step\n",
    "    async def generate_audio(self, ev: PDFEvent) -> AudioEvent:\n",
    "        story = ev.story\n",
    "        save_audio(data, f'{DATA_PATH}/{AUDIO_PATH}' )\n",
    "        return AudioEvent(story=story, pdf=ev.path, path=f'{DATA_PATH}/{AUDIO_PATH}' )\n",
    "\n",
    "    @step\n",
    "    async def generate_video(self, ev: AudioEvent) -> StopEvent:\n",
    "        pdf_to_image(ev.pdf, f'{DATA_PATH}/{IMAGE_PATH}' )\n",
    "        save_audio_video(ev.story, f'{DATA_PATH}/{IMAGE_PATH}' , ev.path, f'{DATA_PATH}/{VIDEO_PATH}' )\n",
    "        save_video(len(ev.story.pages) + 1, f'{DATA_PATH}/{VIDEO_PATH}' , f'{DATA_PATH}/{VIDEO_PATH}/{VIDEO_NAME}')\n",
    "        return StopEvent(result = f'{DATA_PATH}/{VIDEO_PATH}/{VIDEO_NAME}')\n",
    "\n",
    "\n",
    "story_url = \"https://en.wikipedia.org/wiki/The_Sparrow%27s_Lost_Bean\"\n",
    "\n",
    "w = ChildrenStoryGenerationWorkflow(timeout=600, verbose=True)\n",
    "result = await w.run(url = story_url, pdf=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22445c5-de8d-4182-ba04-5f86c107592a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
